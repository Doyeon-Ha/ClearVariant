task_operator_config:
  task: inference
  batch_size: 16